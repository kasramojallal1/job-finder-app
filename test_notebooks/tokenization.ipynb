{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Sub Category Name</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Location</th>\n",
       "      <th>Freelancer Preferred From</th>\n",
       "      <th>Type</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Description</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Client Registration Date</th>\n",
       "      <th>Client City</th>\n",
       "      <th>Client Country</th>\n",
       "      <th>Client Currency</th>\n",
       "      <th>Client Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Banner images for web desgin websites</td>\n",
       "      <td>Design</td>\n",
       "      <td>Entry ($)</td>\n",
       "      <td>Graphic Design</td>\n",
       "      <td>EUR</td>\n",
       "      <td>60.0</td>\n",
       "      <td>remote</td>\n",
       "      <td>ALL</td>\n",
       "      <td>fixed_price</td>\n",
       "      <td>2023-04-29 18:06:39</td>\n",
       "      <td>We are looking to improve the banner images on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-11-03</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>EUR</td>\n",
       "      <td>PPC Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Make my picture a solid silhouette</td>\n",
       "      <td>Video, Photo &amp; Image</td>\n",
       "      <td>Entry ($)</td>\n",
       "      <td>Image Editing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>20.0</td>\n",
       "      <td>remote</td>\n",
       "      <td>ALL</td>\n",
       "      <td>fixed_price</td>\n",
       "      <td>2023-04-29 17:40:28</td>\n",
       "      <td>Hello \\n\\nI need a quick designer to make 4 pi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-21</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GBP</td>\n",
       "      <td>Office manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bookkeeper needed</td>\n",
       "      <td>Business</td>\n",
       "      <td>Entry ($)</td>\n",
       "      <td>Finance &amp; Accounting</td>\n",
       "      <td>GBP</td>\n",
       "      <td>12.0</td>\n",
       "      <td>remote</td>\n",
       "      <td>ALL</td>\n",
       "      <td>fixed_price</td>\n",
       "      <td>2023-04-29 17:40:06</td>\n",
       "      <td>Hi - I need a bookkeeper to assist with bookke...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GBP</td>\n",
       "      <td>Paralegal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title         Category Name Experience  \\\n",
       "0  Banner images for web desgin websites                Design  Entry ($)   \n",
       "1    Make my picture a solid silhouette   Video, Photo & Image  Entry ($)   \n",
       "2                      Bookkeeper needed              Business  Entry ($)   \n",
       "\n",
       "      Sub Category Name Currency  Budget Location Freelancer Preferred From  \\\n",
       "0        Graphic Design      EUR    60.0   remote                       ALL   \n",
       "1         Image Editing      GBP    20.0   remote                       ALL   \n",
       "2  Finance & Accounting      GBP    12.0   remote                       ALL   \n",
       "\n",
       "          Type          Date Posted  \\\n",
       "0  fixed_price  2023-04-29 18:06:39   \n",
       "1  fixed_price  2023-04-29 17:40:28   \n",
       "2  fixed_price  2023-04-29 17:40:06   \n",
       "\n",
       "                                         Description Duration  \\\n",
       "0  We are looking to improve the banner images on...      NaN   \n",
       "1  Hello \\n\\nI need a quick designer to make 4 pi...      NaN   \n",
       "2  Hi - I need a bookkeeper to assist with bookke...      NaN   \n",
       "\n",
       "  Client Registration Date Client City  Client Country Client Currency  \\\n",
       "0               2010-11-03      Dublin         Ireland             EUR   \n",
       "1               2017-02-21      London  United Kingdom             GBP   \n",
       "2               2023-04-09      London  United Kingdom             GBP   \n",
       "\n",
       "  Client Job Title  \n",
       "0   PPC Management  \n",
       "1   Office manager  \n",
       "2        Paralegal  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/freelance-projects.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasra/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-26 23:31:45.152379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-MISC', 'score': 0.82463443, 'index': 23, 'word': 'Python', 'start': 121, 'end': 127}\n",
      "{'entity': 'I-MISC', 'score': 0.96895605, 'index': 25, 'word': 'Ten', 'start': 129, 'end': 132}\n",
      "{'entity': 'I-MISC', 'score': 0.8943534, 'index': 30, 'word': 'S', 'start': 141, 'end': 142}\n",
      "{'entity': 'I-ORG', 'score': 0.84584725, 'index': 39, 'word': 'A', 'start': 186, 'end': 187}\n",
      "{'entity': 'I-ORG', 'score': 0.8937763, 'index': 40, 'word': '##WS', 'start': 187, 'end': 189}\n",
      "{'entity': 'I-MISC', 'score': 0.49700764, 'index': 42, 'word': 'A', 'start': 193, 'end': 194}\n",
      "{'entity': 'I-ORG', 'score': 0.7511189, 'index': 43, 'word': '##zure', 'start': 194, 'end': 198}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "text = \"\"\"We are looking for a Data Scientist with expertise in machine learning, deep learning, and statistics. \n",
    "Skills required: Python, TensorFlow, SQL, and experience with cloud services like AWS or Azure.\"\"\"\n",
    "\n",
    "ner_results = nlp(text)\n",
    "\n",
    "for entity in ner_results:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-MISC', 'score': 0.82463443, 'index': 23, 'word': 'Python', 'start': 121, 'end': 127}\n",
      "{'entity': 'I-MISC', 'score': 0.96895605, 'index': 25, 'word': 'Ten', 'start': 129, 'end': 132}\n",
      "{'entity': 'I-MISC', 'score': 0.8943534, 'index': 30, 'word': 'S', 'start': 141, 'end': 142}\n",
      "{'entity': 'I-ORG', 'score': 0.84584725, 'index': 39, 'word': 'A', 'start': 186, 'end': 187}\n",
      "{'entity': 'I-ORG', 'score': 0.8937763, 'index': 40, 'word': '##WS', 'start': 187, 'end': 189}\n",
      "{'entity': 'I-MISC', 'score': 0.49700764, 'index': 42, 'word': 'A', 'start': 193, 'end': 194}\n",
      "{'entity': 'I-ORG', 'score': 0.7511189, 'index': 43, 'word': '##zure', 'start': 194, 'end': 198}\n"
     ]
    }
   ],
   "source": [
    "for entity in ner_results:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_words(ner_results):\n",
    "    entity_words = []\n",
    "    for entity in ner_results:\n",
    "        entity_words.append(entity['word'])\n",
    "    return entity_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'Ten', 'S', 'A', '##WS', 'A', '##zure']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_asdf = get_entity_words(ner_results)\n",
    "list_asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 59.0/59.0 [00:00<00:00, 63.9kB/s]\n",
      "Downloading config.json: 100%|██████████| 829/829 [00:00<00:00, 1.93MB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 1.24MB/s]\n",
      "Downloading added_tokens.json: 100%|██████████| 2.00/2.00 [00:00<00:00, 5.22kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 794kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 433M/433M [03:06<00:00, 2.33MB/s] \n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'B-ORG', 'score': 0.90113837, 'index': 6, 'word': 'Data', 'start': 21, 'end': 25}\n",
      "{'entity': 'I-MISC', 'score': 0.47391814, 'index': 7, 'word': 'Scientist', 'start': 26, 'end': 35}\n",
      "{'entity': 'B-MISC', 'score': 0.99479914, 'index': 23, 'word': 'Python', 'start': 121, 'end': 127}\n",
      "{'entity': 'B-MISC', 'score': 0.98498034, 'index': 25, 'word': 'TensorFlow', 'start': 129, 'end': 139}\n",
      "{'entity': 'B-MISC', 'score': 0.9969097, 'index': 30, 'word': 'SQL', 'start': 141, 'end': 144}\n",
      "{'entity': 'B-MISC', 'score': 0.69329536, 'index': 39, 'word': 'AWS', 'start': 186, 'end': 189}\n",
      "{'entity': 'B-MISC', 'score': 0.6226404, 'index': 42, 'word': 'Azure', 'start': 193, 'end': 198}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "text = \"\"\"We are looking for a Data Scientist with expertise in machine learning, deep learning, and statistics. \n",
    "Skills required: Python, TensorFlow, SQL, and experience with cloud services like AWS or Azure.\"\"\"\n",
    "\n",
    "ner_results = nlp(text)\n",
    "\n",
    "def merge_subword_tokens(ner_results):\n",
    "    new_results = []\n",
    "    for item in ner_results:\n",
    "        if item['word'].startswith('##'):\n",
    "            if new_results:\n",
    "                new_results[-1]['word'] = new_results[-1]['word'] + item['word'][2:]\n",
    "                new_results[-1]['end'] = item['end']\n",
    "        else:\n",
    "            new_results.append(item)\n",
    "    return new_results\n",
    "\n",
    "merged_results = merge_subword_tokens(ner_results)\n",
    "\n",
    "for entity in merged_results:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "\n",
    "spell = SpellChecker()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    corrected_text = TextBlob(text).correct()\n",
    "\n",
    "    doc = nlp(str(corrected_text))\n",
    "    cleaned_text = \" \".join(token.text for token in doc)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "text = \"We are lookin for a Data Scientst with expertise in machne learning. \\n\\nSkills required: Pythn, TensorFlow, SQL.\"\n",
    "cleaned_text = clean_text(text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
